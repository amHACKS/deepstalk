{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temp3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HzF3R-W3pB"
      },
      "source": [
        "!git clone https://github.com/jkwieser/personality-detection-text.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENrnww5PrvW5"
      },
      "source": [
        "!pip3 install socialreaper==0.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PWwBvUsbOU2"
      },
      "source": [
        "import pickle\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "import plotly.express as px\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from socialreaper import Twitter\r\n",
        "from socialreaper.tools import to_csv\r\n",
        "import re\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "import os\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsXuTInuy6nk"
      },
      "source": [
        "cEXT = pickle.load( open( \"/content/personality-detection-text/data/models/cEXT.p\", \"rb\"))\r\n",
        "cNEU = pickle.load( open( \"/content/personality-detection-text/data/models/cNEU.p\", \"rb\"))\r\n",
        "cAGR = pickle.load( open( \"/content/personality-detection-text/data/models/cAGR.p\", \"rb\"))\r\n",
        "cCON = pickle.load( open( \"/content/personality-detection-text/data/models/cCON.p\", \"rb\"))\r\n",
        "cOPN = pickle.load( open( \"/content/personality-detection-text/data/models/cOPN.p\", \"rb\"))\r\n",
        "vectorizer_31 = pickle.load( open( \"/content/personality-detection-text/data/models/vectorizer_31.p\", \"rb\"))\r\n",
        "vectorizer_30 = pickle.load( open( \"/content/personality-detection-text/data/models/vectorizer_30.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd3ox5EGrtwB"
      },
      "source": [
        "twt = Twitter(app_key=\"\", app_secret=\"\", oauth_token=\"\", \r\n",
        "    oauth_token_secret=\"\")\r\n",
        "    \r\n",
        "user_name=\"narendramodi\"\r\n",
        "\r\n",
        "tweets = twt.user(user_name, \r\n",
        "                  count=1000, \r\n",
        "                  exclude_replies=False, \r\n",
        "                  include_retweets=True)\r\n",
        "    \r\n",
        "to_csv(list(tweets), filename=user_name+'_tweets.csv')\r\n",
        "\r\n",
        "tweets_df = pd.read_csv(user_name+\"_tweets.csv\")\r\n",
        "just_tweets=tweets_df[[\"text\"]]\r\n",
        "##remove urls \r\n",
        "no_urls = just_tweets['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\r\n",
        "#just_text_from_tweets.head(50)\r\n",
        "no_urls=no_urls.to_frame()\r\n",
        "\r\n",
        "# convert rows to a string\r\n",
        "tweets_string = \"\"\r\n",
        "for idx,row in tqdm_notebook(no_urls.iterrows()):\r\n",
        "    tweets_string += (row['text'] + '. ')\r\n",
        "\r\n",
        "clean_text = re.sub(\"[^A-Za-z0-9. ]\",\" \",tweets_string)\r\n",
        "clean_text.strip()\r\n",
        "#no \\ [^A-Za-z0-9 . ]\",\"\r\n",
        "clean_text[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4EPFEsdS8t"
      },
      "source": [
        "def predict_personality(text):\r\n",
        "    sentences = re.split(\"(?<=[.!?]) +\", text)\r\n",
        "    text_vector_31 = vectorizer_31.transform(sentences)\r\n",
        "    text_vector_30 = vectorizer_30.transform(sentences)\r\n",
        "    EXT = cEXT.predict(text_vector_31)\r\n",
        "    NEU = cNEU.predict(text_vector_30)\r\n",
        "    AGR = cAGR.predict(text_vector_31)\r\n",
        "    CON = cCON.predict(text_vector_31)\r\n",
        "    OPN = cOPN.predict(text_vector_31)\r\n",
        "\r\n",
        "    # print(\"EXT\",np.mean(EXT))\r\n",
        "    # print(\"NEU\",np.mean(NEU))\r\n",
        "    # print(\"AGR\",np.mean(AGR))\r\n",
        "    # print(\"CON\",np.mean(CON))\r\n",
        "    # print(\"OPN\",np.mean(OPN))\r\n",
        "\r\n",
        "    return [np.mean(EXT), np.mean(NEU), np.mean(AGR), np.mean(CON), np.mean(OPN)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cig-XJ8RdjI0"
      },
      "source": [
        "text = clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nIU6unxdlVh"
      },
      "source": [
        "predictions = predict_personality(text)\r\n",
        "#print(\"predicted personality:\", predictions)\r\n",
        "df = pd.DataFrame(dict(r=predictions, theta=['EXT','NEU','AGR', 'CON', 'OPN']))\r\n",
        "attrs = list(df['r'])\r\n",
        "\r\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\r\n",
        "plt.style.use('ggplot')\r\n",
        "plt.bar(['EXT','NEU','AGR', 'CON', 'OPN'],attrs, color ='green', alpha=0.5)\r\n",
        "plt.xlabel(\"Attribute\")\r\n",
        "plt.ylabel(\"Tendency\")\r\n",
        "plt.title(\"Personality Report\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kLgm62xEi2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}