{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temp3.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HzF3R-W3pB"
      },
      "source": [
        "!git clone https://github.com/jkwieser/personality-detection-text.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENrnww5PrvW5"
      },
      "source": [
        "!pip3 install socialreaper==0.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PWwBvUsbOU2"
      },
      "source": [
        "import pickle\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "import plotly.express as px\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "\r\n",
        "from socialreaper import Twitter\r\n",
        "from socialreaper.tools import to_csv\r\n",
        "import re\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "import os\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd3ox5EGrtwB"
      },
      "source": [
        "twt = Twitter(app_key=\"D4ZZmYaatUIesltdD7ilZ5VK9\", app_secret=\"D3KjNfxvLoRBrffHYkajfukEneLqcUs0mUoeJbazrFDyzgckBW\", oauth_token=\"1292034807057149952-yxoCr1imusLdTbP1FohM8DEsUFISRU\", \r\n",
        "    oauth_token_secret=\"Zem3oIHV5ujHEnzATgUBnEqRNOXhpfzNCzmxnZFmmoc3K\")\r\n",
        "    \r\n",
        "user_name=\"POTUS\"\r\n",
        "tweets = twt.user(user_name, \r\n",
        "                  count=10, \r\n",
        "                  exclude_replies=True, \r\n",
        "                  include_retweets=False)\r\n",
        "    \r\n",
        "to_csv(list(tweets), filename=user_name+'_tweets.csv')\r\n",
        "\r\n",
        "tweets_df = pd.read_csv(user_name+\"_tweets.csv\")\r\n",
        "just_tweets=tweets_df[[\"text\"]]\r\n",
        "##remove urls \r\n",
        "no_urls = just_tweets['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\r\n",
        "#just_text_from_tweets.head(50)\r\n",
        "no_urls=no_urls.to_frame()\r\n",
        "\r\n",
        "# convert rows to a string\r\n",
        "tweets_string = \"\"\r\n",
        "for idx,row in tqdm_notebook(no_urls.iterrows()):\r\n",
        "    tweets_string += (row['text'] + '. ')\r\n",
        "\r\n",
        "clean_text = re.sub(\"[^A-Za-z0-9.]\",\" \",tweets_string)\r\n",
        "clean_text.strip()\r\n",
        "#no \\ [^A-Za-z0-9 . ]\",\"\r\n",
        "clean_text[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ3mNRCsdQXy"
      },
      "source": [
        "cEXT = pickle.load( open( \"/content/personality-detection-text/data/models/cEXT.p\", \"rb\"))\r\n",
        "cNEU = pickle.load( open( \"/content/personality-detection-text/data/models/cNEU.p\", \"rb\"))\r\n",
        "cAGR = pickle.load( open( \"/content/personality-detection-text/data/models/cAGR.p\", \"rb\"))\r\n",
        "cCON = pickle.load( open( \"/content/personality-detection-text/data/models/cCON.p\", \"rb\"))\r\n",
        "cOPN = pickle.load( open( \"/content/personality-detection-text/data/models/cOPN.p\", \"rb\"))\r\n",
        "vectorizer_31 = pickle.load( open( \"/content/personality-detection-text/data/models/vectorizer_31.p\", \"rb\"))\r\n",
        "vectorizer_30 = pickle.load( open( \"/content/personality-detection-text/data/models/vectorizer_30.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4EPFEsdS8t"
      },
      "source": [
        "def predict_personality(text):\r\n",
        "    sentences = re.split(\"(?<=[.!?]) +\", text)\r\n",
        "    text_vector_31 = vectorizer_31.transform(sentences)\r\n",
        "    text_vector_30 = vectorizer_30.transform(sentences)\r\n",
        "    EXT = cEXT.predict(text_vector_31)\r\n",
        "    NEU = cNEU.predict(text_vector_30)\r\n",
        "    AGR = cAGR.predict(text_vector_31)\r\n",
        "    CON = cCON.predict(text_vector_31)\r\n",
        "    OPN = cOPN.predict(text_vector_31)\r\n",
        "    return [EXT[0], NEU[0], AGR[0], CON[0], OPN[0]]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cig-XJ8RdjI0"
      },
      "source": [
        "text = clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nIU6unxdlVh"
      },
      "source": [
        "predictions = predict_personality(text)\r\n",
        "print(\"predicted personality:\", predictions)\r\n",
        "df = pd.DataFrame(dict(r=predictions, theta=['EXT','NEU','AGR', 'CON', 'OPN']))\r\n",
        "df.head()\r\n",
        "fig = px.line_polar(df, r='r', theta='theta', line_close=True)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTgrKymOdm3J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}