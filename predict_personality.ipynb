{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "big5_showcase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mainakdeb/e_summit/blob/main/predict_personality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF0-f9Vj8i2W"
      },
      "source": [
        "This notebook demostrates how our script works. Check out the main code here - https://github.com/Mainakdeb/e_summit\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub3aEUZUGfMr"
      },
      "source": [
        "## Clone our repository to access training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjIk_8vQC1uA",
        "outputId": "faf8a7b1-8616-49c9-fb96-bdcf04c5b73b"
      },
      "source": [
        "!git clone https://github.com/Mainakdeb/e_summit.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'e_summit'...\n",
            "remote: Enumerating objects: 310, done.\u001b[K\n",
            "remote: Total 310 (delta 0), reused 0 (delta 0), pack-reused 310\u001b[K\n",
            "Receiving objects: 100% (310/310), 10.16 MiB | 7.85 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGDKHqThEeKp"
      },
      "source": [
        "## Install socialreaper version 0.3.0\r\n",
        "Most of the dependencies needed are already available in colab, when running the script locally, make sure to run \r\n",
        "```\r\n",
        "pip install -r requirements.txt\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ReyKVIEV5T",
        "outputId": "619b79e1-c412-451a-bdcc-f64fe9df1b30"
      },
      "source": [
        "!pip3 install socialreaper==0.3.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting socialreaper==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/db/b4/c2999e4d21c3ed9112f87ef2838b7e4e338f0da28bf76fd704fffe4fefea/socialreaper-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from socialreaper==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from socialreaper==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from socialreaper==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->socialreaper==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->socialreaper==0.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->socialreaper==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->socialreaper==0.3.0) (3.0.4)\n",
            "Installing collected packages: socialreaper\n",
            "Successfully installed socialreaper-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHKGxZlTEWow"
      },
      "source": [
        "import optparse\r\n",
        "import pickle\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\r\n",
        "#from data_prep import DataPrep\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "from socialreaper import Twitter\r\n",
        "from socialreaper.tools import to_csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFy6RTnvGS1H"
      },
      "source": [
        "## Train Classifier:\r\n",
        "Run the following cell to begin training. It requires approximately 5 minutes.\r\n",
        "\r\n",
        "In case you dont want to train, you can access pretrained models from this [Google drive link](https://drive.google.com/drive/folders/1oG_EZlshqx3leaMN41mQsZLKeYZdKocD?usp=sharing). Add the folder as shortcut to your drive and run the following code in a new cell\r\n",
        "```\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "```\r\n",
        "Now you'll get access to google drive folders from colab.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS2GnRBX3NIV",
        "outputId": "af079a1f-e524-40ea-b97f-53c5382dcb36"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataPrep():\n",
        "    def __init__(self):\n",
        "        self.trait_cat_dict = {\n",
        "            'O': 'cOPN',\n",
        "            'C': 'cCON',\n",
        "            'E': 'cEXT',\n",
        "            'A': 'cAGR',\n",
        "            'N': 'cNEU',\n",
        "            'OPN': 'cOPN',\n",
        "            'CON': 'cCON',\n",
        "            'EXT': 'cEXT',\n",
        "            'AGR': 'cAGR',\n",
        "            'NEU': 'cNEU',\n",
        "            'Openness': 'cOPN',\n",
        "            'Conscientiousness': 'cCON',\n",
        "            'Extraversion': 'cEXT',\n",
        "            'Agreeableness': 'cAGR',\n",
        "            'Neuroticism': 'cNEU'\n",
        "            }\n",
        "        self.trait_score_dict = {\n",
        "            'O': 'sOPN',\n",
        "            'C': 'sCON',\n",
        "            'E': 'sEXT',\n",
        "            'A': 'sAGR',\n",
        "            'N': 'sNEU',\n",
        "            'OPN': 'sOPN',\n",
        "            'CON': 'sCON',\n",
        "            'EXT': 'sEXT',\n",
        "            'AGR': 'sAGR',\n",
        "            'NEU': 'sNEU',\n",
        "            'Openness': 'sOPN',\n",
        "            'Conscientiousness': 'sCON',\n",
        "            'Extraversion': 'sEXT',\n",
        "            'Agreeableness': 'sAGR',\n",
        "            'Neuroticism': 'sNEU'\n",
        "            }\n",
        "        self.LIWC_features = [\n",
        "            'WPS', 'Unique', 'Dic', 'Sixltr', 'Negate', 'Assent', 'Article', 'Preps', 'Number',\n",
        "            'Pronoun', 'I', 'We', 'Self', 'You', 'Other',\n",
        "            'Affect', 'Posemo', 'Posfeel', 'Optim', 'Negemo', 'Anx', 'Anger', 'Sad',\n",
        "            'Cogmech', 'Cause', 'Insight', 'Discrep', 'Inhib', 'Tentat', 'Certain',\n",
        "            'Senses', 'See', 'Hear', 'Feel',\n",
        "            'Social', 'Comm', 'Othref', 'Friends', 'Family', 'Humans',\n",
        "            'Time', 'Past', 'Present', 'Future',\n",
        "            'Space', 'Up', 'Down', 'Incl', 'Excl', 'Motion',\n",
        "            'Occup', 'School', 'Job', 'Achieve',\n",
        "            'Leisure', 'Home', 'Sports', 'TV', 'Music',\n",
        "            'Money',\n",
        "            'Metaph', 'Relig', 'Death', 'Physcal', 'Body', 'Sexual', 'Eating', 'Sleep', 'Groom',\n",
        "            'Allpct', 'Period', 'Comma', 'Colon', 'Semic', 'Qmark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'Otherp',\n",
        "            'Swear', 'Nonfl', 'Fillers',\n",
        "        ]\n",
        "\n",
        "    def prep_data(self, type, trait, regression=False, model_comparison=False):\n",
        "        df_status = self.prep_status_data()\n",
        "        tfidf = TfidfVectorizer(stop_words='english', strip_accents='ascii')\n",
        "        if type == 'essay':\n",
        "            if model_comparison:\n",
        "                X = tfidf.fit_transform(df_essay['TEXT'])\n",
        "            else:\n",
        "                X = df_essay['TEXT']\n",
        "\n",
        "            y_column = self.trait_cat_dict[trait]\n",
        "            y = df_essay[y_column]\n",
        "\n",
        "        elif type == 'status':\n",
        "            other_features_columns = [\n",
        "                'NETWORKSIZE',\n",
        "                'BETWEENNESS',\n",
        "                'NBETWEENNESS',\n",
        "                'DENSITY',\n",
        "                'BROKERAGE',\n",
        "                'NBROKERAGE',\n",
        "                'TRANSITIVITY'\n",
        "            ]\n",
        "            if model_comparison:\n",
        "                X = tfidf.fit_transform(df_status['STATUS'])\n",
        "                # X = np.nan_to_num(np.column_stack((result, df_status[other_features_columns])))\n",
        "            # Data to fit production model\n",
        "            else:\n",
        "                X = df_status['STATUS']\n",
        "            if regression:\n",
        "                y_column = self.trait_score_dict[trait]\n",
        "            else:\n",
        "                y_column = self.trait_cat_dict[trait]\n",
        "            y = df_status[y_column]\n",
        "        return X, y\n",
        "\n",
        "    def prep_status_data(self):\n",
        "        df = pd.read_csv('/content/e_summit/data/mypersonality_final.csv', encoding=\"ISO-8859-1\")\n",
        "        df = self.convert_traits_to_boolean(df)\n",
        "        return df\n",
        "\n",
        "    def prep_essay_data(self):\n",
        "        df_essays = pd.read_csv('data/personality-detection-my-copy/essays.csv', encoding=\"ISO-8859-1\")\n",
        "        df_mairesse = pd.read_csv('data/personality-detection-my-copy/mairesse.csv', encoding=\"ISO-8859-1\", header=None)\n",
        "        df_mairesse.columns = ['#AUTHID'] + self.LIWC_features\n",
        "        df = df_essays.merge(df_mairesse, how = 'inner', on = ['#AUTHID'])\n",
        "        # add word count (WC) column\n",
        "        df['WC'] = df['TEXT'].str.split().str.len()\n",
        "        df = self.convert_traits_to_boolean(df)\n",
        "        return df\n",
        "\n",
        "    def convert_traits_to_boolean(self, df):\n",
        "        trait_columns = ['cOPN', 'cCON', 'cEXT', 'cAGR', 'cNEU']\n",
        "        d = {'y': True, 'n': False}\n",
        "\n",
        "        for trait in trait_columns:\n",
        "            df[trait] = df[trait].map(d)\n",
        "        return df\n",
        "\n",
        "    def load_data(self, filepath):\n",
        "        return pd.read_csv(filepath, encoding=\"ISO-8859-1\")\n",
        "        \n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.rfr = RandomForestRegressor(bootstrap=True,\n",
        "         max_features='sqrt',\n",
        "         min_samples_leaf=1,\n",
        "         min_samples_split=2,\n",
        "         n_estimators= 200)\n",
        "        self.rfc = RandomForestClassifier(max_features='sqrt', n_estimators=110)\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english', strip_accents='ascii')\n",
        "\n",
        "    def fit(self, X, y, regression=True):\n",
        "        X = self.tfidf.fit_transform(X)\n",
        "        if regression:\n",
        "            self.rfr = self.rfr.fit(X, y)\n",
        "        else:\n",
        "            self.rfc = self.rfc.fit(X, y)\n",
        "\n",
        "    def predict(self, X, regression=True):\n",
        "        X = self.tfidf.transform(X)\n",
        "        if regression:\n",
        "            return self.rfr.predict(X)\n",
        "        else:\n",
        "            return self.rfc.predict(X)\n",
        "\n",
        "    def predict_proba(self, X, regression=False):\n",
        "        X = self.tfidf.transform(X)\n",
        "        if regression:\n",
        "            raise ValueError('Cannot predict probabilites of a regression!')\n",
        "        else:\n",
        "            return self.rfc.predict_proba(X)\n",
        "\n",
        "traits = ['OPN', 'CON', 'EXT', 'AGR', 'NEU']\n",
        "model = Model()\n",
        "\n",
        "for trait in traits:\n",
        "    dp = DataPrep()\n",
        "    X_regression, y_regression = dp.prep_data('status', trait, regression=True, model_comparison=False)\n",
        "    X_categorical, y_categorical = dp.prep_data('status', trait, regression=False, model_comparison=False)\n",
        "    print('Fitting trait ' + trait + ' regression model...')\n",
        "    model.fit(X_regression, y_regression, regression=True)\n",
        "    print('Done!')\n",
        "    print('Fitting trait ' + trait + ' categorical model...')\n",
        "    model.fit(X_categorical, y_categorical, regression=False)\n",
        "    print('Done!')\n",
        "    with open('/content/' + trait + '_model.pkl', 'wb') as f:\n",
        "        # Write the model to a file.\n",
        "        pickle.dump(model, f)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting trait OPN regression model...\n",
            "Done!\n",
            "Fitting trait OPN categorical model...\n",
            "Done!\n",
            "Fitting trait CON regression model...\n",
            "Done!\n",
            "Fitting trait CON categorical model...\n",
            "Done!\n",
            "Fitting trait EXT regression model...\n",
            "Done!\n",
            "Fitting trait EXT categorical model...\n",
            "Done!\n",
            "Fitting trait AGR regression model...\n",
            "Done!\n",
            "Fitting trait AGR categorical model...\n",
            "Done!\n",
            "Fitting trait NEU regression model...\n",
            "Done!\n",
            "Fitting trait NEU categorical model...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU2XkIYs-ycm"
      },
      "source": [
        "## Load the classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5x3gEshyylN"
      },
      "source": [
        "import pickle\r\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\r\n",
        "#from data_prep import DataPrep\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "class Model():\r\n",
        "    def __init__(self):\r\n",
        "        self.rfr = RandomForestRegressor(bootstrap=True,\r\n",
        "         max_features='sqrt',\r\n",
        "         min_samples_leaf=1,\r\n",
        "         min_samples_split=2,\r\n",
        "         n_estimators= 200)\r\n",
        "        self.rfc = RandomForestClassifier(max_features='sqrt', n_estimators=110)\r\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english', strip_accents='ascii')\r\n",
        "\r\n",
        "    def fit(self, X, y, regression=True):\r\n",
        "        X = self.tfidf.fit_transform(X)\r\n",
        "        if regression:\r\n",
        "            self.rfr = self.rfr.fit(X, y)\r\n",
        "        else:\r\n",
        "            self.rfc = self.rfc.fit(X, y)\r\n",
        "\r\n",
        "    def predict(self, X, regression=True):\r\n",
        "        X = self.tfidf.transform(X)\r\n",
        "        if regression:\r\n",
        "            return self.rfr.predict(X)\r\n",
        "        else:\r\n",
        "            return self.rfc.predict(X)\r\n",
        "\r\n",
        "    def predict_proba(self, X, regression=False):\r\n",
        "        X = self.tfidf.transform(X)\r\n",
        "        if regression:\r\n",
        "            raise ValueError('Cannot predict probabilites of a regression!')\r\n",
        "        else:\r\n",
        "            return self.rfc.predict_proba(X)\r\n",
        "\r\n",
        "M = Model()\r\n",
        "models={}\r\n",
        "traits = ['OPN', 'CON', 'EXT', 'AGR', 'NEU']\r\n",
        "for trait in traits:\r\n",
        "    with open('/content/' + trait + '_model.pkl', 'rb') as f:\r\n",
        "        models[trait] = pickle.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WApCmIZh-5a8"
      },
      "source": [
        "## Define get_profile( ):\r\n",
        "the get_profile( ) function takes keywords/names as input and returns corresponding social media id's as a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr03RPrZzMBD"
      },
      "source": [
        "from googlesearch import search\r\n",
        "import re\r\n",
        "\r\n",
        "def get_profile(keyword):\r\n",
        "  print(\"getting profiles from google..\")\r\n",
        "  results = list(search(keyword, num=10))\r\n",
        "  profiles = {\r\n",
        "      'twitter': ''\r\n",
        "  }\r\n",
        "  for r in results:\r\n",
        "    if r.find('twitter') != -1 and profiles['twitter'] == '':\r\n",
        "      r = re.search(r'https://twitter.com/([^/?]+)', r).group(1)\r\n",
        "      profiles['twitter'] = r\r\n",
        "\r\n",
        "  return profiles"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx6kpvn8_SoV"
      },
      "source": [
        "## Define get_text_from_tweets( ) :\r\n",
        "this function below takes the twitter username (string) as input, then gets rid of special characters using regex, and returns tweets corresponding to that user in form of a string. \r\n",
        "\r\n",
        "In the main script, we have saved the scraped tweets as information.txt to adhere with the problem statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-aHRJDzz5n"
      },
      "source": [
        "twt = Twitter(app_key=\"\", \r\n",
        "              app_secret=\"\", \r\n",
        "              oauth_token=\"\", \r\n",
        "              oauth_token_secret=\"\")\r\n",
        "    \r\n",
        "def get_text_from_tweets(user_name):\r\n",
        "    print(\"processing text from tweets..\")\r\n",
        "    tweets = twt.user(user_name, \r\n",
        "                    count=1000, \r\n",
        "                    exclude_replies=False, \r\n",
        "                    include_retweets=True)\r\n",
        "        \r\n",
        "    to_csv(list(tweets), filename=user_name+'_tweets.csv')\r\n",
        "\r\n",
        "    tweets_df = pd.read_csv(user_name+\"_tweets.csv\")\r\n",
        "    just_tweets=tweets_df[[\"text\"]]\r\n",
        "    ##remove urls \r\n",
        "    no_urls = just_tweets['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\r\n",
        "    #just_text_from_tweets.head(50)\r\n",
        "    no_urls=no_urls.to_frame()\r\n",
        "\r\n",
        "    # convert rows to a string\r\n",
        "    tweets_string = \"\"\r\n",
        "    for idx,row in no_urls.iterrows():\r\n",
        "        tweets_string += (row['text'] + '. ')\r\n",
        "\r\n",
        "    clean_text = re.sub(\"[^A-Za-z0-9. ]\",\" \",tweets_string)\r\n",
        "    clean_text = clean_text.strip()\r\n",
        "    return(clean_text)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6IFNlQUAEF2"
      },
      "source": [
        "## Define predict_personality( )\r\n",
        "This function accepts a string as input and returns an array of floats, each corresponding to one of 5 personality traits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuFhpYU8z9v7"
      },
      "source": [
        "def predict(X):\r\n",
        "        X=[X]\r\n",
        "        predictions = {}\r\n",
        "        traits = ['OPN', 'CON', 'EXT', 'AGR', 'NEU']\r\n",
        "        for trait in traits:\r\n",
        "            pkl_model = models[trait]\r\n",
        "            trait_scores = pkl_model.predict(X, regression=True).reshape(1, -1)\r\n",
        "            # scaler = MinMaxScaler(feature_range=(0, 50))\r\n",
        "            # print(scaler.fit_transform(trait_scores))\r\n",
        "            # scaled_trait_scores = scaler.fit_transform(trait_scores)\r\n",
        "            predictions['pred_s'+trait] = trait_scores.flatten()[0]\r\n",
        "            # predictions['pred_s'+trait] = scaled_trait_scores.flatten()\r\n",
        "\r\n",
        "            trait_categories = pkl_model.predict(X, regression=False)\r\n",
        "            predictions['pred_c'+trait] = str(trait_categories[0])\r\n",
        "            # predictions['pred_c'+trait] = trait_categories\r\n",
        "\r\n",
        "            trait_categories_probs = pkl_model.predict_proba(X)\r\n",
        "            predictions['pred_prob_c'+trait] = trait_categories_probs[:, 1][0]\r\n",
        "            # predictions['pred_prob_c'+trait] = trait_categories_probs[:, 1]\r\n",
        "        return predictions"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vMmBUvjAoLp"
      },
      "source": [
        "## Define display_results( ):\r\n",
        "This function plots a bar chart, representing each of the 5 OCEAN tendencies of the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q6wirOs6_F8"
      },
      "source": [
        "import plotly.graph_objs as go\r\n",
        "from plotly.offline import iplot"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmU7sLWf2VzD"
      },
      "source": [
        "def display_results(predictions, user_name):\r\n",
        "    attrs = [predictions['pred_prob_cOPN'],\r\n",
        "             predictions['pred_prob_cCON'],\r\n",
        "             predictions['pred_prob_cEXT'],\r\n",
        "             predictions['pred_prob_cAGR'],\r\n",
        "             predictions['pred_prob_cNEU']]\r\n",
        "\r\n",
        "    y=attrs\r\n",
        "    t=[str(i*100)[0:5]+\"%\" for i in y]\r\n",
        "    x=['Openness','Conscientiousness','Extraverison','Agreeableness','Neuroticism']\r\n",
        "    colors=['lightblue','lightsalmon','pink', 'lightgreen', 'indianred']\r\n",
        "    data = [go.Bar(x = x, \r\n",
        "                   y = y, \r\n",
        "                   text=t,\r\n",
        "                   textposition='auto'\r\n",
        "                   )]\r\n",
        "\r\n",
        "    fig = go.Figure(data=data)\r\n",
        "\r\n",
        "    fig.update_traces(marker_color=colors, marker_line_color='rgb(8,48,107)',\r\n",
        "                  marker_line_width=1.5, opacity=0.7)\r\n",
        "    \r\n",
        "    #fig.update_traces(texttemplate=, textposition='outside')\r\n",
        "\r\n",
        "    fig.update_layout(title_text=user_name+\"'s personality report\")\r\n",
        "    fig.update_layout(yaxis_tickformat = '%')\r\n",
        "\r\n",
        "\r\n",
        "    iplot(fig)\r\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVE5llsPBHMF"
      },
      "source": [
        "##Moment of truth:\r\n",
        "Feel free to replace Elon Musk with Chetan Bhagat, Ratan Tata etc.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnrzc3rO1KWk",
        "outputId": "d07f9498-d600-43ab-f5a4-031560b1b3c9"
      },
      "source": [
        "user_name = get_profile(\"elonmusk\")['twitter']\r\n",
        "text = get_text_from_tweets(user_name)\r\n",
        "predictions = predict(text)\r\n",
        "#display_results(predictions=predictions, user_name=user_name)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting profiles from google..\n",
            "processing text from tweets..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj_krQsXVxTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "163d840d-61b6-45d4-933a-f2dad04cd510"
      },
      "source": [
        "display_results(predictions=predictions, user_name=user_name)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c05dc21f-ebfc-4bfa-8f3e-ee5ec1478a99\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c05dc21f-ebfc-4bfa-8f3e-ee5ec1478a99\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c05dc21f-ebfc-4bfa-8f3e-ee5ec1478a99',\n",
              "                        [{\"marker\": {\"color\": [\"lightblue\", \"lightsalmon\", \"pink\", \"lightgreen\", \"indianred\"], \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"opacity\": 0.7, \"text\": [\"78.18%\", \"12.72%\", \"17.72%\", \"66.58%\", \"15.0%\"], \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"Openness\", \"Conscientiousness\", \"Extraverison\", \"Agreeableness\", \"Neuroticism\"], \"y\": [0.7818181818181819, 0.12727272727272726, 0.17727272727272728, 0.6658471084109957, 0.15]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"elonmusk's personality report\"}, \"yaxis\": {\"tickformat\": \"%\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c05dc21f-ebfc-4bfa-8f3e-ee5ec1478a99');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAIfRVHg0Wsx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}